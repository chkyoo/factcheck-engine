"""
RSS ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ (Option A)
ì£¼ìš” ì–¸ë¡ ì‚¬ RSS í”¼ë“œë¥¼ ìˆ˜ì§‘í•˜ê³  íŒ©íŠ¸ì²´í¬ ëŒ€ìƒ í•„í„°ë§
"""

import feedparser
import sqlite3
from datetime import datetime
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from article_extractor import ArticleExtractor
from claim_detector import ClaimDetector
from priority_scorer import PriorityScorer


class RSSMonitor:
    """RSS í”¼ë“œ ëª¨ë‹ˆí„°"""
    
    # ì£¼ìš” ì–¸ë¡ ì‚¬ RSS í”¼ë“œ
    RSS_FEEDS = {
        'êµ¬ê¸€_ì •ì¹˜': 'https://news.google.com/rss/headlines/section/topic/POLITICS?hl=ko&gl=KR&ceid=KR:ko',
        'êµ¬ê¸€_ê²½ì œ': 'https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=ko&gl=KR&ceid=KR:ko',
        'êµ¬ê¸€_ì‚¬íšŒ': 'https://news.google.com/rss/headlines/section/topic/NATION?hl=ko&gl=KR&ceid=KR:ko',
    }
    
    # ê´€ì‹¬ í‚¤ì›Œë“œ
    KEYWORDS = [
        'í†µê³„', 'ì¡°ì‚¬', 'ë°œí‘œ', 'ì¦ê°€', 'ê°ì†Œ', 'ìƒìŠ¹', 'í•˜ë½',
        'ì„¸ê¸ˆ', 'ì›”ì„¸', 'ì „ì„¸', 'ë¶€ë™ì‚°', 'ì‘ê¸‰ì‹¤', 'ì‚¬ë§',
        'ê²½ì œì„±ì¥ë¥ ', 'GDP', 'ë¶€ì±„', 'ê¸ˆë¦¬', 'ë¬¼ê°€'
    ]
    
    def __init__(self, db_path='data/articles.db'):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()
        
        self.extractor = ArticleExtractor()
        self.detector = ClaimDetector()
        self.scorer = PriorityScorer()
    
    def _init_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT UNIQUE,
                title TEXT,
                source TEXT,
                published_date TEXT,
                collected_date TEXT,
                priority_score INTEGER,
                should_factcheck BOOLEAN,
                analyzed BOOLEAN DEFAULT 0
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def collect_feeds(self):
        """RSS í”¼ë“œ ìˆ˜ì§‘"""
        print("=" * 70)
        print(f"RSS í”¼ë“œ ìˆ˜ì§‘ ì‹œì‘ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
        print()
        
        total_articles = 0
        keyword_matched = 0
        high_priority = 0
        
        # User-Agent ì„¤ì • (ë„¤ì´ë²„ ì°¨ë‹¨ ë°©ì§€)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        import requests
        
        for feed_name, feed_url in self.RSS_FEEDS.items():
            print(f"ğŸ“¡ {feed_name} ìˆ˜ì§‘ ì¤‘...")
            
            try:
                # requestsë¡œ ë¨¼ì € ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                response = requests.get(feed_url, headers=headers, timeout=10)
                response.raise_for_status()
                
                # feedparserë¡œ íŒŒì‹±
                feed = feedparser.parse(response.text)
                articles = feed.entries
                
                print(f"  âœ“ {len(articles)}ê°œ ê¸°ì‚¬ ë°œê²¬")
                total_articles += len(articles)
                
                for entry in articles:
                    # í‚¤ì›Œë“œ í•„í„°ë§
                    title = entry.get('title', '')
                    summary = entry.get('summary', '')
                    
                    if self._has_keyword(title + ' ' + summary):
                        keyword_matched += 1
                        
                        # DBì— ì €ì¥
                        url = entry.get('link', '')
                        published = entry.get('published', datetime.now().strftime('%Y-%m-%d'))
                        
                        if self._save_article(url, title, feed_name, published):
                            high_priority += 1
                
            except Exception as e:
                print(f"  âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
            print()
        
        print("=" * 70)
        print("ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"  â€¢ ì´ ê¸°ì‚¬: {total_articles}ê°œ")
        print(f"  â€¢ í‚¤ì›Œë“œ ë§¤ì¹­: {keyword_matched}ê°œ")
        print(f"  â€¢ íŒ©íŠ¸ì²´í¬ ëŒ€ìƒ: {high_priority}ê°œ")
        print("=" * 70)
        print()
    
    def _has_keyword(self, text: str) -> bool:
        """í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€"""
        for keyword in self.KEYWORDS:
            if keyword in text:
                return True
        return False
    
    def _save_article(self, url: str, title: str, source: str, published: str) -> bool:
        """ê¸°ì‚¬ ì €ì¥ ë° ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # ì¤‘ë³µ ì²´í¬
            cursor.execute('SELECT id FROM articles WHERE url = ?', (url,))
            if cursor.fetchone():
                return False
            
            # ê°„ë‹¨í•œ ìš°ì„ ìˆœìœ„ ê³„ì‚° (ì œëª©ë§Œìœ¼ë¡œ)
            # ì‹¤ì œ ë³¸ë¬¸ ë¶„ì„ì€ ë‚˜ì¤‘ì— ë³„ë„ë¡œ ìˆ˜í–‰
            score = 0
            if any(kw in title for kw in ['ì¦ê°€', 'ê°ì†Œ', 'í­ì¦', 'ê¸‰ì¦']):
                score += 30
            if any(kw in title for kw in ['í†µê³„', 'ì¡°ì‚¬', 'ë°œí‘œ']):
                score += 20
            
            should_factcheck = score >= 30
            
            cursor.execute('''
                INSERT INTO articles (url, title, source, published_date, collected_date, priority_score, should_factcheck)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (url, title, source, published, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), score, should_factcheck))
            
            conn.commit()
            return should_factcheck
            
        except sqlite3.IntegrityError:
            return False
        finally:
            conn.close()
    
    def get_pending_articles(self, limit=10):
        """ë¶„ì„ ëŒ€ê¸° ì¤‘ì¸ ê¸°ì‚¬ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT url, title, source, priority_score
            FROM articles
            WHERE should_factcheck = 1 AND analyzed = 0
            ORDER BY priority_score DESC
            LIMIT ?
        ''', (limit,))
        
        articles = cursor.fetchall()
        conn.close()
        
        return articles


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    monitor = RSSMonitor()
    monitor.collect_feeds()
    
    # ëŒ€ê¸° ì¤‘ì¸ ê¸°ì‚¬ í‘œì‹œ
    pending = monitor.get_pending_articles()
    
    if pending:
        print()
        print("ğŸ“‹ íŒ©íŠ¸ì²´í¬ ëŒ€ê¸° ëª©ë¡")
        print("-" * 70)
        
        for i, (url, title, source, score) in enumerate(pending, 1):
            print(f"\n[{i}] {title}")
            print(f"    ì–¸ë¡ ì‚¬: {source} | ì ìˆ˜: {score}ì ")
            print(f"    URL: {url}")
        
        print()
        print("-" * 70)


if __name__ == "__main__":
    main()
